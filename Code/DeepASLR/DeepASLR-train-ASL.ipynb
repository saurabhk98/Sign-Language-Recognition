{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7a6496b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 22:00:26.476087: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.utils import plot_model\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ead2a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(filename):\n",
    "    with open(filename) as training_file:\n",
    "        csv_reader = csv.reader(training_file, delimiter=',')\n",
    "        first_line = True\n",
    "        temp_images = []\n",
    "        temp_labels = []\n",
    "        for row in csv_reader:\n",
    "            if first_line:\n",
    "                first_line = False\n",
    "            else:\n",
    "                temp_labels.append(row[0])\n",
    "                image_data = row[1:785]\n",
    "                image_data_as_array = np.array_split(image_data, 28)\n",
    "                temp_images.append(image_data_as_array)\n",
    "        images = np.array(temp_images).astype('float')\n",
    "        labels = np.array(temp_labels).astype('float')\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be37ca67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27455, 28, 28)\n",
      "(27455,)\n",
      "(7172, 28, 28)\n",
      "(7172,)\n"
     ]
    }
   ],
   "source": [
    "train_path = './data/sign_mnist_train/sign_mnist_train.csv'\n",
    "test_path = './data/sign_mnist_test/sign_mnist_test.csv'\n",
    "\n",
    "training_images, training_labels = get_data(train_path)\n",
    "testing_images, testing_labels = get_data(test_path)\n",
    "\n",
    "print(training_images.shape)\n",
    "print(training_labels.shape)\n",
    "print(testing_images.shape)\n",
    "print(testing_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48e1810d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27455, 28, 28, 1)\n",
      "(7172, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# Data Augmentation\n",
    "training_images = np.expand_dims(training_images, axis=3)\n",
    "testing_images = np.expand_dims(testing_images, axis=3)\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "print(training_images.shape)\n",
    "print(testing_images.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2744608a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = train_datagen.flow(\n",
    "    training_images, training_labels,\n",
    "    batch_size=32,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_set = train_datagen.flow(\n",
    "    testing_images, testing_labels,\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a5a36d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 22:00:57.415818: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 3, 3, 128)         73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 1, 1, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 26)                6682      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 132,378\n",
      "Trainable params: 132,378\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Steps per epoch :  857.96875\n",
      "validation_steps :  224.125\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 22:00:57.724032: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "858/857 [==============================] - ETA: 0s - loss: 2.8379 - accuracy: 0.1304"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 22:02:31.131717: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "857/857 [==============================] - 98s 113ms/step - loss: 2.8379 - accuracy: 0.1304 - val_loss: 2.4323 - val_accuracy: 0.2359\n",
      "Epoch 2/50\n",
      "857/857 [==============================] - 86s 100ms/step - loss: 2.1022 - accuracy: 0.3243 - val_loss: 1.8307 - val_accuracy: 0.3977\n",
      "Epoch 3/50\n",
      "857/857 [==============================] - 93s 108ms/step - loss: 1.6860 - accuracy: 0.4488 - val_loss: 1.6138 - val_accuracy: 0.4681\n",
      "Epoch 4/50\n",
      "857/857 [==============================] - 90s 104ms/step - loss: 1.4435 - accuracy: 0.5254 - val_loss: 1.3852 - val_accuracy: 0.5287\n",
      "Epoch 5/50\n",
      "857/857 [==============================] - 89s 103ms/step - loss: 1.2645 - accuracy: 0.5800 - val_loss: 1.3312 - val_accuracy: 0.5485\n",
      "Epoch 6/50\n",
      "857/857 [==============================] - 83s 96ms/step - loss: 1.1157 - accuracy: 0.6294 - val_loss: 1.1607 - val_accuracy: 0.6097\n",
      "Epoch 7/50\n",
      "857/857 [==============================] - 79s 92ms/step - loss: 1.0195 - accuracy: 0.6594 - val_loss: 1.0849 - val_accuracy: 0.6341\n",
      "Epoch 8/50\n",
      "857/857 [==============================] - 75s 87ms/step - loss: 0.9352 - accuracy: 0.6854 - val_loss: 1.0342 - val_accuracy: 0.6545\n",
      "Epoch 9/50\n",
      "857/857 [==============================] - 77s 90ms/step - loss: 0.8751 - accuracy: 0.7048 - val_loss: 1.0020 - val_accuracy: 0.6637\n",
      "Epoch 10/50\n",
      "857/857 [==============================] - 76s 89ms/step - loss: 0.8161 - accuracy: 0.7244 - val_loss: 0.9882 - val_accuracy: 0.6722\n",
      "Epoch 11/50\n",
      "857/857 [==============================] - 83s 96ms/step - loss: 0.7724 - accuracy: 0.7410 - val_loss: 0.8703 - val_accuracy: 0.7047\n",
      "Epoch 12/50\n",
      "857/857 [==============================] - 82s 95ms/step - loss: 0.7280 - accuracy: 0.7509 - val_loss: 0.8818 - val_accuracy: 0.7043\n",
      "Epoch 13/50\n",
      "857/857 [==============================] - 79s 92ms/step - loss: 0.7003 - accuracy: 0.7628 - val_loss: 0.7864 - val_accuracy: 0.7302\n",
      "Epoch 14/50\n",
      "857/857 [==============================] - 81s 95ms/step - loss: 0.6630 - accuracy: 0.7727 - val_loss: 0.7648 - val_accuracy: 0.7462\n",
      "Epoch 15/50\n",
      "857/857 [==============================] - 80s 93ms/step - loss: 0.6386 - accuracy: 0.7843 - val_loss: 0.7873 - val_accuracy: 0.7331\n",
      "Epoch 16/50\n",
      "857/857 [==============================] - 78s 91ms/step - loss: 0.6082 - accuracy: 0.7907 - val_loss: 0.6569 - val_accuracy: 0.7684\n",
      "Epoch 17/50\n",
      "857/857 [==============================] - 73s 85ms/step - loss: 0.6082 - accuracy: 0.7937 - val_loss: 0.7513 - val_accuracy: 0.7414\n",
      "Epoch 18/50\n",
      "857/857 [==============================] - 79s 92ms/step - loss: 0.5754 - accuracy: 0.8048 - val_loss: 0.7120 - val_accuracy: 0.7589\n",
      "Epoch 19/50\n",
      "857/857 [==============================] - 76s 88ms/step - loss: 0.5594 - accuracy: 0.8095 - val_loss: 0.6490 - val_accuracy: 0.7743\n",
      "Epoch 20/50\n",
      "857/857 [==============================] - 94s 109ms/step - loss: 0.5522 - accuracy: 0.8127 - val_loss: 0.6445 - val_accuracy: 0.7754\n",
      "Epoch 21/50\n",
      "857/857 [==============================] - 95s 111ms/step - loss: 0.5306 - accuracy: 0.8196 - val_loss: 0.6146 - val_accuracy: 0.7910\n",
      "Epoch 22/50\n",
      "857/857 [==============================] - 94s 110ms/step - loss: 0.5069 - accuracy: 0.8278 - val_loss: 0.6060 - val_accuracy: 0.7909\n",
      "Epoch 23/50\n",
      "857/857 [==============================] - 94s 109ms/step - loss: 0.5081 - accuracy: 0.8256 - val_loss: 0.5875 - val_accuracy: 0.8031\n",
      "Epoch 24/50\n",
      "857/857 [==============================] - 94s 109ms/step - loss: 0.4814 - accuracy: 0.8365 - val_loss: 0.5667 - val_accuracy: 0.8088\n",
      "Epoch 25/50\n",
      "857/857 [==============================] - 94s 109ms/step - loss: 0.4732 - accuracy: 0.8390 - val_loss: 0.5609 - val_accuracy: 0.8065\n",
      "Epoch 26/50\n",
      "857/857 [==============================] - 81s 94ms/step - loss: 0.4766 - accuracy: 0.8407 - val_loss: 0.5810 - val_accuracy: 0.8020\n",
      "Epoch 27/50\n",
      "857/857 [==============================] - 95s 110ms/step - loss: 0.4635 - accuracy: 0.8423 - val_loss: 0.5605 - val_accuracy: 0.8097\n",
      "Epoch 28/50\n",
      "857/857 [==============================] - 88s 103ms/step - loss: 0.4450 - accuracy: 0.8479 - val_loss: 0.5189 - val_accuracy: 0.8260\n",
      "Epoch 29/50\n",
      "857/857 [==============================] - 94s 109ms/step - loss: 0.4391 - accuracy: 0.8484 - val_loss: 0.5596 - val_accuracy: 0.8084\n",
      "Epoch 30/50\n",
      "857/857 [==============================] - 96s 112ms/step - loss: 0.4300 - accuracy: 0.8519 - val_loss: 0.5857 - val_accuracy: 0.8024\n",
      "Epoch 31/50\n",
      "857/857 [==============================] - 93s 109ms/step - loss: 0.4346 - accuracy: 0.8545 - val_loss: 0.5352 - val_accuracy: 0.8208\n",
      "Epoch 32/50\n",
      "857/857 [==============================] - 93s 108ms/step - loss: 0.4207 - accuracy: 0.8587 - val_loss: 0.5586 - val_accuracy: 0.8120\n",
      "Epoch 33/50\n",
      "857/857 [==============================] - 87s 101ms/step - loss: 0.4056 - accuracy: 0.8616 - val_loss: 0.5276 - val_accuracy: 0.8260\n",
      "Epoch 34/50\n",
      "857/857 [==============================] - 91s 106ms/step - loss: 0.4053 - accuracy: 0.8632 - val_loss: 0.6274 - val_accuracy: 0.7921\n",
      "Epoch 35/50\n",
      "857/857 [==============================] - 84s 98ms/step - loss: 0.4042 - accuracy: 0.8634 - val_loss: 0.5322 - val_accuracy: 0.8218\n",
      "Epoch 36/50\n",
      "857/857 [==============================] - 69s 80ms/step - loss: 0.4017 - accuracy: 0.8649 - val_loss: 0.5229 - val_accuracy: 0.8190\n",
      "Epoch 37/50\n",
      "857/857 [==============================] - 74s 86ms/step - loss: 0.3832 - accuracy: 0.8686 - val_loss: 0.5260 - val_accuracy: 0.8259\n",
      "Epoch 38/50\n",
      "857/857 [==============================] - 79s 92ms/step - loss: 0.3852 - accuracy: 0.8721 - val_loss: 0.5027 - val_accuracy: 0.8299\n",
      "Epoch 39/50\n",
      "857/857 [==============================] - 89s 103ms/step - loss: 0.3779 - accuracy: 0.8715 - val_loss: 0.5621 - val_accuracy: 0.8153\n",
      "Epoch 40/50\n",
      "857/857 [==============================] - 91s 106ms/step - loss: 0.3797 - accuracy: 0.8698 - val_loss: 0.4874 - val_accuracy: 0.8384\n",
      "Epoch 41/50\n",
      "857/857 [==============================] - 78s 91ms/step - loss: 0.3688 - accuracy: 0.8746 - val_loss: 0.4898 - val_accuracy: 0.8397\n",
      "Epoch 42/50\n",
      "857/857 [==============================] - 78s 91ms/step - loss: 0.3586 - accuracy: 0.8777 - val_loss: 0.4745 - val_accuracy: 0.8415\n",
      "Epoch 43/50\n",
      "857/857 [==============================] - 87s 102ms/step - loss: 0.3584 - accuracy: 0.8782 - val_loss: 0.4945 - val_accuracy: 0.8309\n",
      "Epoch 44/50\n",
      "857/857 [==============================] - 74s 86ms/step - loss: 0.3623 - accuracy: 0.8787 - val_loss: 0.4363 - val_accuracy: 0.8588\n",
      "Epoch 45/50\n",
      "857/857 [==============================] - 79s 92ms/step - loss: 0.3553 - accuracy: 0.8796 - val_loss: 0.4701 - val_accuracy: 0.8473\n",
      "Epoch 46/50\n",
      "857/857 [==============================] - 82s 95ms/step - loss: 0.3493 - accuracy: 0.8812 - val_loss: 0.4381 - val_accuracy: 0.8544\n",
      "Epoch 47/50\n",
      "857/857 [==============================] - 94s 109ms/step - loss: 0.3546 - accuracy: 0.8788 - val_loss: 0.4431 - val_accuracy: 0.8491\n",
      "Epoch 48/50\n",
      "857/857 [==============================] - 99s 115ms/step - loss: 0.3523 - accuracy: 0.8791 - val_loss: 0.4507 - val_accuracy: 0.8523\n",
      "Epoch 49/50\n",
      "857/857 [==============================] - 99s 115ms/step - loss: 0.3395 - accuracy: 0.8858 - val_loss: 0.4835 - val_accuracy: 0.8441\n",
      "Epoch 50/50\n",
      "857/857 [==============================] - 85s 99ms/step - loss: 0.3376 - accuracy: 0.8858 - val_loss: 0.4281 - val_accuracy: 0.8600\n"
     ]
    }
   ],
   "source": [
    "# CNN Model\n",
    "classifier = Sequential()\n",
    "\n",
    "# First layer\n",
    "# classifier.add(Convolution2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))\n",
    "classifier.add(Convolution2D(32, (3, 3), input_shape = (28, 28, 1), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Second layer\n",
    "classifier.add(Convolution2D(64, (3, 3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Third layer\n",
    "classifier.add(Convolution2D(128, (3, 3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Flattening\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Classification\n",
    "classifier.add(Dense(256, activation='relu'))\n",
    "classifier.add(Dense(26, activation='softmax'))\n",
    "\n",
    "# Run the CNN model\n",
    "# classifier.compile(loss='categorical_crossentropy',\n",
    "classifier.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Display the model summary\n",
    "classifier.summary()\n",
    "\n",
    "# model = classifier.fit(\n",
    "#         training_images,\n",
    "#         steps_per_epoch=800,\n",
    "#         epochs=25,\n",
    "#         validation_data = testing_images,\n",
    "#         validation_steps = 6500\n",
    "#       )\n",
    "print('Steps per epoch : ', len(training_images) / 32)\n",
    "print('validation_steps : ', len(testing_images) / 32)\n",
    "\n",
    "model = classifier.fit(\n",
    "    training_set,\n",
    "    steps_per_epoch=len(training_images) / 32,  # Adjust steps_per_epoch\n",
    "    epochs=50,\n",
    "    validation_data=test_set,\n",
    "    validation_steps=len(testing_images) / 32  # Adjust validation_steps\n",
    ")\n",
    "\n",
    "\n",
    "classifier.save(\"classifier_CNN_MNIST_1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bd80f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8be478a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the history to a JSON file\n",
    "with open('training_history.json', 'w') as f:\n",
    "    json.dump(model.history, f)\n",
    "\n",
    "# To load the history\n",
    "with open('training_history.json', 'r') as f:\n",
    "    loaded_history = json.load(f)\n",
    "\n",
    "# Access loaded history\n",
    "loaded_train_accuracy = loaded_history['accuracy']\n",
    "loaded_test_accuracy = loaded_history['val_accuracy']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env_tf",
   "language": "python",
   "name": "ml_env_tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
